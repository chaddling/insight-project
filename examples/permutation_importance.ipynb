{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgu/anaconda3/envs/cgu-py36/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.44021359,  1.6902414 , -0.02933151, -0.98009167, -0.48452405],\n",
       "       [ 1.66325794, -0.07596626,  0.17343286,  1.03378327, -0.48452405],\n",
       "       [-0.81503802, -1.30951611, -4.73423637,  0.52779312, -0.48452405],\n",
       "       ...,\n",
       "       [ 1.78386201, -0.91052048, -0.73385516,  0.48007219,  2.37872215],\n",
       "       [ 0.89260491,  0.45522693, -0.63960993,  1.19740062, -0.48452405],\n",
       "       [ 1.11499354, -0.22785182, -0.07240274,  0.92677964,  1.42430675]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 3\n",
    "\n",
    "data = pd.read_csv('../data/features_vec_all.csv')\n",
    "\n",
    "feature_names = ['num_pre', 'num_post', 'mean_time', 'len_description',\n",
    "       'num_movies', 'num_images', 'is_action', 'is_adventure',\n",
    "       'is_casual', 'is_mmo', 'is_racing', 'is_rpg', 'is_simulation',\n",
    "       'is_sports', 'is_strategy']\n",
    "\n",
    "X = data[feature_names]\n",
    "\n",
    "# log transform on the data and rescale\n",
    "for i in X.index:\n",
    "    X.at[i, 'num_pre'] = np.log(1 + 100*X.at[i, 'num_pre'])\n",
    "    X.at[i,'num_post'] = np.log(1 + 200*X.at[i,'num_post'])\n",
    "    X.at[i,'mean_time'] = np.log(1 + 200*X.at[i,'mean_time'])\n",
    "    X.at[i,'len_description'] = np.log(1+X.at[i,'len_description'])\n",
    "\n",
    "X = X.values\n",
    "Y = data['sentiment'].values\n",
    "\n",
    "# rescale only the continuous variables by (x- mu) / std\n",
    "scaler = StandardScaler(copy=False)\n",
    "scaler.fit_transform(X[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.3)\n",
    "\n",
    "X_resampled, Y_resampled = SMOTE().fit_resample(X_train, Y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10,\n",
    "                            max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on training data\n",
      "[[4186  279  629]\n",
      " [1643 1410 2041]\n",
      " [ 493  607 3994]]\n",
      "0.5981068946853596\n",
      "confusion matrix on test data\n",
      "[[  36   47  112]\n",
      " [ 126  213  590]\n",
      " [ 212  250 1721]]\n",
      "0.3899542833348451\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_resampled, Y_resampled)\n",
    "\n",
    "Y_pred = rf.predict(X_resampled)\n",
    "print('confusion matrix on training data')\n",
    "print(confusion_matrix(Y_resampled, Y_pred))\n",
    "print(f1_score(Y_resampled, Y_pred, average='macro'))\n",
    "\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "print('confusion matrix on test data')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(rf, X, Y):\n",
    "    \n",
    "    classes = {0:-1, 1:0, 2:1}\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_classes = len(np.unique(Y))\n",
    "    \n",
    "    for tree in rf.estimators_:\n",
    "        unsampled_indices = _generate_unsampled_indices(tree.random_state, n_samples)\n",
    "        tree_preds = tree.predict(X[unsampled_indices, :])\n",
    "\n",
    "    # need to relabel because the predict method produces class labels (0, 1, 2)\n",
    "    Y_preds = [classes[tree_preds[i]] for i in range(len(tree_preds))]\n",
    "        \n",
    "    return f1_score(Y_preds, Y[unsampled_indices], average='macro')\n",
    "        \n",
    "\n",
    "# X, Y are training data/target\n",
    "def permutation_importance(rf, X, Y, metric):\n",
    "    \n",
    "    if not hasattr(rf, 'estimators_'):\n",
    "        rf.fit(X, Y)\n",
    "    \n",
    "    baseline_score = metric(rf, X, Y)\n",
    "    importances = []\n",
    "    \n",
    "    num_cols = X.shape[1] # number of columns/features\n",
    "    \n",
    "    X_train = X.copy()\n",
    "    \n",
    "    for k in range(num_cols):\n",
    "        save = X_train[:,k:k+1].copy()\n",
    "        X_train[:,k:k+1] = np.random.permutation(X_train[:,k:k+1]) # permute value of this\n",
    "        \n",
    "        permuted_score = metric(rf, X_train, Y)\n",
    "        X_train[:,k:k+1] = save\n",
    "        \n",
    "        importances.append(baseline_score - permuted_score)\n",
    "    \n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutation importance =0.014397522498943941 +/-0.016817341826894483\n",
      "[0.009503373250978553, 0.049537309251046435, 0.009478763677066349, 0.0005967343138573167, 0.004322480217065328, 0.017245943281857967, 0.009034151035248572, 0.012238645697513262, 0.03524830120367689, 0.0, 0.0, 0.006721092081611202, 0.009133614617474473, 0.0, 0.05290242885676277]\n"
     ]
    }
   ],
   "source": [
    "imp = permutation_importance(rf, X_resampled, Y_resampled, f1)\n",
    "print('permutation importance ={} +/-{}'.format(np.mean(imp), np.std(imp)))\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00066194,  0.01007265,  0.00035529, -0.00053539,  0.00285996,\n",
       "       -0.00352   ,  0.01365503,  0.00801022,  0.00631834,  0.00577723,\n",
       "        0.00065584,  0.00054276,  0.01931771, -0.00106626,  0.01529574])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = PermutationImportance(rf, scoring='f1_macro').fit(X_test, Y_test)\n",
    "A.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
